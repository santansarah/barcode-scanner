{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb2znHC7t5AigY5k8BpxSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santansarah/barcode-scanner/blob/main/item_to_item_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is usually the Android part of my videos, but today, I'm here in Colab with my final model. I've gone ahead & run everything already so we don't have to wait for the scripts to execute. This way, I can just go through each block step by step.\n",
        "\n",
        "First, I install everything that I'll need for this model. Most importantly, I'll be using the `tensorflow-recommenders` API to subclass my combined model and run the `Retrieval` task.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jUHW6fe5xAL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPH9PBcbY4Fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f99e78-9181-4cc0-948c-3f9501d64a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q tensorflow-datasets\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q numpy\n",
        "!pip install -q Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I add all of my imports."
      ],
      "metadata": {
        "id": "Q7LVT3-C69wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "vK2sccc7ZEYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUlG6gFatTpi",
        "outputId": "0b34bd77-c524-489a-8068-6fb996376036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I uploaded my Open Food Facts CSV file to Google Drive, so I could easily acess it from Colab. In this block, I connect to drive, and create a symbolic link so I can access it as `/mydrive`."
      ],
      "metadata": {
        "id": "_O7GxLO27Esa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7nK4md8ZMek",
        "outputId": "ebdea8cf-f09e-44f2-8615-e19881374ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go head an take a look at this file, before we start the preprocessing steps:\n",
        "https://drive.google.com/file/d/18FOEN6thUGgZx-8WdeA74YQRp4I1BLiJ/view?usp=sharing"
      ],
      "metadata": {
        "id": "hLCC5QCKmMW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a handy function to clean my CSV file. As we saw, some of the fat & carb values are floats, so I round them to solid Integers. I also drop any null data."
      ],
      "metadata": {
        "id": "2oMC_6e78-px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(df_data):\n",
        "    ## check NaNs and drop rows if any\n",
        "    print(df_data.isnull().sum())\n",
        "    df_data.dropna(inplace=True)\n",
        "    df_data[\"fat_value\"] = df_data[\"fat_value\"].round(0).astype(int)\n",
        "    df_data[\"carbohydrates_value\"] = df_data[\"carbohydrates_value\"].round(0).astype(int)\n",
        "    return df_data"
      ],
      "metadata": {
        "id": "_7gaJ48vw_R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I load up my data with Pandas. One small, tricky thing here - and yet very important, is that the `code` column imports as an Integer by default. This is a HUGE problem, because this drops the two 0's in front of some of the barcodes. That means that when I pass in a barcode from my Android app, they won't match, and the datatypes will be different. I easily got around this by specifying the `dtype` of `str` for the `code` column."
      ],
      "metadata": {
        "id": "RdVLnwRu9T9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barcodes_df = pd.read_csv('/mydrive/food_data/food-final.csv', dtype={'code': str}) \n",
        "barcodes_df = pre_process(barcodes_df.filter(['code', 'product_name_en', 'fat_value', 'carbohydrates_value']))"
      ],
      "metadata": {
        "id": "Ltk33wePoUPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b3d6d1-a5de-47ba-91a6-a50c4ad563a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code                     0\n",
            "product_name_en         31\n",
            "fat_value              395\n",
            "carbohydrates_value    388\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data's all loaded, I create my custom `food_diet_type` column. This block is slightly different than the example from my earlier slide. After learning more about feature preprocessing and Text embeddings, I decided to make the diet type a numeric categorical range from `1-5`."
      ],
      "metadata": {
        "id": "yL4Y5W0a-Y0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditions = {\n",
        "    1: (barcodes_df['carbohydrates_value'] >= 30),\n",
        "    2: (barcodes_df['fat_value'] >= 5) & (barcodes_df['carbohydrates_value'] <= 12),\n",
        "    3: (barcodes_df['fat_value'] <= 1) & (barcodes_df['carbohydrates_value'] <= 1),\n",
        "    4: (barcodes_df['fat_value'] <= 3)\n",
        "}\n",
        "barcodes_df['food_diet_type'] = np.select(conditions.values(), conditions.keys(), default=5).astype(int)"
      ],
      "metadata": {
        "id": "URNm9Kgd-ZnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how the final preprocessed data looks:"
      ],
      "metadata": {
        "id": "JR9A2cj6E-vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(barcodes_df))\n",
        "barcodes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "ZCCx3OPglePD",
        "outputId": "721e34c6-8de6-494e-8376-92ddcbd16d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               code                                 product_name_en  \\\n",
              "0     0078742367194                              Omega -3 trail mix   \n",
              "1     0078742370828                   Complete pancake & waffle mix   \n",
              "2     0078742082752                       Chunk Light Tuna In Water   \n",
              "4     0078742371825                                 Brown Gravy Mix   \n",
              "5     0078742144603  Naturally & Artificially Fruit-Flavored Snacks   \n",
              "...             ...                                             ...   \n",
              "3697  0078742136288   Organic great value, fruit spread, strawberry   \n",
              "3698  0099482454494                            Great Northern Beans   \n",
              "3699  0099482452759                            Great Northern Beans   \n",
              "3700  0078742065007   Great value, frosted toaster pastries, cherry   \n",
              "3701  0078742064482    Great value, chicken seasoning & coating mix   \n",
              "\n",
              "      fat_value  carbohydrates_value  food_diet_type  \n",
              "0            44                   33               1  \n",
              "1             3                   74               1  \n",
              "2             1                    0               3  \n",
              "4             8                   50               1  \n",
              "5             2                   77               1  \n",
              "...         ...                  ...             ...  \n",
              "3697          0                   58               1  \n",
              "3698          1                   63               1  \n",
              "3699          0                   15               4  \n",
              "3700         10                   71               1  \n",
              "3701          6                   62               1  \n",
              "\n",
              "[3303 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a3d615d-291b-4674-bdfb-f82e6e0e6cb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>product_name_en</th>\n",
              "      <th>fat_value</th>\n",
              "      <th>carbohydrates_value</th>\n",
              "      <th>food_diet_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0078742367194</td>\n",
              "      <td>Omega -3 trail mix</td>\n",
              "      <td>44</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0078742370828</td>\n",
              "      <td>Complete pancake &amp; waffle mix</td>\n",
              "      <td>3</td>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0078742082752</td>\n",
              "      <td>Chunk Light Tuna In Water</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0078742371825</td>\n",
              "      <td>Brown Gravy Mix</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0078742144603</td>\n",
              "      <td>Naturally &amp; Artificially Fruit-Flavored Snacks</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3697</th>\n",
              "      <td>0078742136288</td>\n",
              "      <td>Organic great value, fruit spread, strawberry</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3698</th>\n",
              "      <td>0099482454494</td>\n",
              "      <td>Great Northern Beans</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3699</th>\n",
              "      <td>0099482452759</td>\n",
              "      <td>Great Northern Beans</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3700</th>\n",
              "      <td>0078742065007</td>\n",
              "      <td>Great value, frosted toaster pastries, cherry</td>\n",
              "      <td>10</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3701</th>\n",
              "      <td>0078742064482</td>\n",
              "      <td>Great value, chicken seasoning &amp; coating mix</td>\n",
              "      <td>6</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3303 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a3d615d-291b-4674-bdfb-f82e6e0e6cb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a3d615d-291b-4674-bdfb-f82e6e0e6cb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a3d615d-291b-4674-bdfb-f82e6e0e6cb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I create my training, validation, and test dataframes from my food data import. There are so many ways to do this - np.split was really easy, and works OK for this model. This method allocates about 80% of the data to the training dataset, and about 10% to the validation and test datasets. I think I need to revisit this later, and definitely add more data to my validation and test datasets, but for now, this works fine."
      ],
      "metadata": {
        "id": "e3dHS_RJFGw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, test = np.split(barcodes_df.sample(frac=1), [int(0.8*len(barcodes_df)), int(0.9*len(barcodes_df))])\n",
        "\n",
        "print(len(train), 'training examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZX4y1k1vvPp",
        "outputId": "49b12bd3-0378-4814-f42e-d94d36dd4958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2642 training examples\n",
            "330 validation examples\n",
            "331 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fit my model, these dataframes then need to be converted to tensor datasets."
      ],
      "metadata": {
        "id": "LYdzVJ6KGEwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(dict(test))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(dict(val))"
      ],
      "metadata": {
        "id": "nIqnTT6ov51v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I get a list of only the barcodes, just like Movie Titles from the TensorFlow tutorial."
      ],
      "metadata": {
        "id": "LT7uFgYjGWxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "barcodes = train_ds.map(lambda x: x[\"code\"])"
      ],
      "metadata": {
        "id": "QaFD5vAv_umj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(barcodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_H8JqCzTgJq",
        "outputId": "d456e83d-48bd-43cb-8852-d641f0b9b3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2642"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I prepare for my Embedding layers by getting all of my unique features, which in my case is:\n",
        "- Barcodes as String\n",
        "- Fat Value as Int\n",
        "- Carbohydrates Value as Int\n",
        "- Food Diet Types as Int"
      ],
      "metadata": {
        "id": "HrSIT_WXGfl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_barcodes = np.unique(np.concatenate(list(barcodes.batch(500))))\n",
        "print(unique_barcodes)\n",
        "\n",
        "unique_user_fat = tf.range(1,200)\n",
        " \n",
        "unique_user_carbs = tf.range(1,200)\n",
        "print(unique_user_carbs)\n",
        "\n",
        "unique_diet_types = tf.range(1,6)\n",
        "print(unique_diet_types)"
      ],
      "metadata": {
        "id": "2F5laVDk7aMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c0145a-f64b-45d7-e5ef-def4eb19d51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'000158230404573973194' b'0008749315577' b'0012142013718' ...\n",
            " b'87421415' b'87545463' b'915732']\n",
            "tf.Tensor(\n",
            "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
            "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
            "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
            "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
            "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
            " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
            " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
            " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
            " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
            " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
            " 199], shape=(199,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, I'm ready to build my models. The TensorFlow MovieLens Tutorial just creates a simple `user_model`:\n",
        "\n",
        "```\n",
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  # We add an additional embedding to account for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])\n",
        "```\n",
        "\n",
        "But since I needed to add several embedding layers, here, I inherit from `tf.keras.Model`. This ItemModel includes all of the item features that I want my model to consider during the retrieval process. In this model, I use my unique feature arrays to create my Sequential Embeding layers. The barcode is a StringLookup, and the rest are IntegerLookups."
      ],
      "metadata": {
        "id": "Llo7oWWcG2IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.item_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=unique_barcodes, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_barcodes) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    # Just to note - order is important here! When I had diet_type\n",
        "    # below fat & carbs, it made a difference. I still need to learn\n",
        "    # about weights, and how I can build better relationships between\n",
        "    # my features.\n",
        "    self.diet_type_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.IntegerLookup(\n",
        "              vocabulary=unique_diet_types, mask_token=None),\n",
        "          tf.keras.layers.Embedding(len(unique_diet_types) + 1, 32),\n",
        "      ]) \n",
        "\n",
        "    self.fat_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.IntegerLookup(\n",
        "            vocabulary=unique_user_fat, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_fat) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    self.carbs_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.IntegerLookup(\n",
        "            vocabulary=unique_user_carbs, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_carbs) + 1, 32),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.item_embedding(inputs[\"code\"]),\n",
        "        self.diet_type_embedding(inputs[\"food_diet_type\"]),\n",
        "        self.fat_embedding(inputs[\"fat_value\"]),\n",
        "        self.carbs_embedding(inputs[\"carbohydrates_value\"])\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "PEn6eJunIyIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I expand on my ItemModel to create a deeper retrieval model. This QueryModel adds the emedding layers by calling `self.embedding_model = ItemModel()`, then, it adds the Dense layers, and sets their activation to `relu`. This can help capture complex relationships between my features - hopefully fat & carbs! `layer_sizes` is a parameter, so I can experiment with deeper model sizes, for example I could start with [32], then [64,32], then try [128, 64, 32]. So far though, my initial tests show that creating a deeper model doesn't come back with great results - this might be because my dataset is too small, and I'm **overfitting**. But for now, I'm leaving it here in case I want to expand, and continue to experiment."
      ],
      "metadata": {
        "id": "-demGL_bIGLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "  \"\"\"Model for encoding user queries.\"\"\"\n",
        " \n",
        "  def __init__(self, layer_sizes):\n",
        "    \"\"\"Model for encoding user queries.\n",
        " \n",
        "    Args:\n",
        "      layer_sizes:\n",
        "        A list of integers where the i-th entry represents the number of units\n",
        "        the i-th layer contains.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        " \n",
        "    # We first use the item model for generating embeddings.\n",
        "    self.embedding_model = ItemModel()\n",
        " \n",
        "    # Then construct the layers.\n",
        "    self.dense_layers = tf.keras.Sequential()\n",
        " \n",
        "    # Use the ReLU activation for all but the last layer.\n",
        "    for layer_size in layer_sizes[:-1]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        " \n",
        "    # No activation for the last layer.\n",
        "    for layer_size in layer_sizes[-1:]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "     \n",
        "  def call(self, inputs):\n",
        "    feature_embedding = self.embedding_model(inputs)\n",
        "    return self.dense_layers(feature_embedding)\n",
        "  "
      ],
      "metadata": {
        "id": "9ot-V0B_Wpjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next block creates the embedding layer for the Candidate model, which in my case is the list of barcodes from my CSV. Embedding layers convert raw values to usable, trainable formats. Here, I add a `barcode_vectorizer` - this step is really important, so that I'm able to pass a raw string from my Android app. Otherwise, if the TextVectorization did not occur in the model, I believe I'd have to export ALL of the integer barcode mappings to a JSON file. Then, I'd have to include that JSON file in my app or serve it up from an API, and lookup the corresponding barcode-to-integer values. This is one of those lessons that I had to learn the hard way, when I was using my `food_diet_type` as a string in one of my earlier models. ðŸ¤ª"
      ],
      "metadata": {
        "id": "Oyj-A2v9K4SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BarcodeModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.barcode_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "          vocabulary=unique_barcodes, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_barcodes) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    # Here I set up the vectorizer \n",
        "    self.barcode_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    # Then I create the text embedding\n",
        "    self.barcode_text_embedding = tf.keras.Sequential([\n",
        "      self.barcode_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    # And by calling adapt on the unique list of barcodes here\n",
        "    # inside the model, I believe this is the final step that\n",
        "    # allows me to pass a regular string array from Android.\n",
        "    self.barcode_vectorizer.adapt(barcodes)\n",
        "\n",
        "  def call(self, barcodes):\n",
        "    return tf.concat([\n",
        "        self.barcode_embedding(barcodes),\n",
        "        self.barcode_text_embedding(barcodes),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "HJl06Wj3McM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the QueryModel, this model just combines the embedding layers w/the deeper Dense layers."
      ],
      "metadata": {
        "id": "7AXuUBZ2LnZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateModel(tf.keras.Model):\n",
        "  \"\"\"Model for encoding movies.\"\"\"\n",
        " \n",
        "  def __init__(self, layer_sizes):\n",
        "    \"\"\"Model for encoding movies.\n",
        " \n",
        "    Args:\n",
        "      layer_sizes:\n",
        "        A list of integers where the i-th entry represents the number of units\n",
        "        the i-th layer contains.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        " \n",
        "    self.embedding_model = BarcodeModel()\n",
        " \n",
        "    # Then construct the layers.\n",
        "    self.dense_layers = tf.keras.Sequential()\n",
        " \n",
        "    # Use the ReLU activation for all but the last layer.\n",
        "    for layer_size in layer_sizes[:-1]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        " \n",
        "    # No activation for the last layer.\n",
        "    for layer_size in layer_sizes[-1:]:\n",
        "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "     \n",
        "  def call(self, inputs):\n",
        "    feature_embedding = self.embedding_model(inputs)\n",
        "    return self.dense_layers(feature_embedding)\n",
        "  "
      ],
      "metadata": {
        "id": "bjk8rQkmW4aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to combine everything together, into one final model. This model sets up the QueryModel, the CandiateModel, and defines the Retrieval task. Let's say we pass a barcode of 888. When using FactorizedTopK metrics, the model will check to see how often that same barcode is returned in the retrieval query. This helps determine the model's categorical accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "vFBTFymSLt3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommendModel(tfrs.models.Model):\n",
        " \n",
        "  def __init__(self, layer_sizes):\n",
        "    super().__init__()\n",
        "    self.query_model = QueryModel(layer_sizes)\n",
        "    self.candidate_model = CandidateModel(layer_sizes)\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=barcodes.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        " \n",
        "  # This is the loss function that defines the embeddings, then returns\n",
        "  # the retrieval task.\n",
        "  def compute_loss(self, features, training=False):\n",
        " \n",
        "    query_embeddings = self.query_model({\n",
        "        \"code\": features[\"code\"],\n",
        "        \"food_diet_type\": features[\"food_diet_type\"],  \n",
        "        \"fat_value\": features[\"fat_value\"],\n",
        "        \"carbohydrates_value\": features[\"carbohydrates_value\"]\n",
        "    })\n",
        "    candidate_embeddings = self.candidate_model(features[\"code\"])\n",
        " \n",
        "    return self.task(\n",
        "        query_embeddings, candidate_embeddings, compute_metrics=not training)"
      ],
      "metadata": {
        "id": "1OtIt9iRXCKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caching the training dataset improves performance, allowing the second interation over the dataset to be much faster than the first one. If you cache your training set, make sure that you also cache your test and validation datasets or you might have issues when you fit your model."
      ],
      "metadata": {
        "id": "xYM3Ne37H1Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train_ds.shuffle(len(train_ds)).batch(500).cache()\n",
        "cached_test = test_ds.batch(50).cache()\n",
        "cached_val = val_ds.batch(50).cache()"
      ],
      "metadata": {
        "id": "NElUYpVV3rMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With everything set up, it's time to create and use the combined model. "
      ],
      "metadata": {
        "id": "sBO-_rBYOyDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, I go ahead and instantiate a shallow model. Then I compile it.\n",
        "model = RecommendModel([32])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "# Next, I fit the model with my cached datasets. \n",
        "model.fit(cached_train, epochs=50, validation_data=cached_val)\n",
        "\n",
        "# When it's done, it will print out my TopK accuracy scores. I don't think \n",
        "# that I'm getting good evaluation numbers yet - I think that's because I'm\n",
        "# not working with enough data yet. This is something I need to revisit in the\n",
        "# future.\n",
        "train_accuracy = model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "test_accuracy = model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "\n",
        "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
        "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "JjXkL75O_8G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e40e57b-f6a7-49bb-c3c3-f860cc39f1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 12s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2420.5639 - regularization_loss: 0.0000e+00 - total_loss: 2420.5639 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 1s 261ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2161.4767 - regularization_loss: 0.0000e+00 - total_loss: 2161.4767 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 1s 261ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2308.0103 - regularization_loss: 0.0000e+00 - total_loss: 2308.0103 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 1s 261ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1661.5502 - regularization_loss: 0.0000e+00 - total_loss: 1661.5502 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 1s 202ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1126.2788 - regularization_loss: 0.0000e+00 - total_loss: 1126.2788 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 3s 517ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 737.5120 - regularization_loss: 0.0000e+00 - total_loss: 737.5120 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 481.4712 - regularization_loss: 0.0000e+00 - total_loss: 481.4712 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 1s 201ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 305.3340 - regularization_loss: 0.0000e+00 - total_loss: 305.3340 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 1s 263ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 153.1717 - regularization_loss: 0.0000e+00 - total_loss: 153.1717 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 1s 261ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 69.2197 - regularization_loss: 0.0000e+00 - total_loss: 69.2197 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 26.4351 - regularization_loss: 0.0000e+00 - total_loss: 26.4351 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13.6956 - regularization_loss: 0.0000e+00 - total_loss: 13.6956 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 3s 517ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 6.7312 - regularization_loss: 0.0000e+00 - total_loss: 6.7312 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 4.8965 - regularization_loss: 0.0000e+00 - total_loss: 4.8965 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 3.9988 - regularization_loss: 0.0000e+00 - total_loss: 3.9988 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 1s 197ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 3.3947 - regularization_loss: 0.0000e+00 - total_loss: 3.3947 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2.9466 - regularization_loss: 0.0000e+00 - total_loss: 2.9466 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2.5998 - regularization_loss: 0.0000e+00 - total_loss: 2.5998 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 3s 523ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2.3233 - regularization_loss: 0.0000e+00 - total_loss: 2.3233 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 2.0976 - regularization_loss: 0.0000e+00 - total_loss: 2.0976 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.9101 - regularization_loss: 0.0000e+00 - total_loss: 1.9101 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.7517 - regularization_loss: 0.0000e+00 - total_loss: 1.7517 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.6164 - regularization_loss: 0.0000e+00 - total_loss: 1.6164 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 3s 526ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.4994 - regularization_loss: 0.0000e+00 - total_loss: 1.4994 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.3973 - regularization_loss: 0.0000e+00 - total_loss: 1.3973 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.3075 - regularization_loss: 0.0000e+00 - total_loss: 1.3075 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.2279 - regularization_loss: 0.0000e+00 - total_loss: 1.2279 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.1569 - regularization_loss: 0.0000e+00 - total_loss: 1.1569 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.0932 - regularization_loss: 0.0000e+00 - total_loss: 1.0932 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 3s 525ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 1.0357 - regularization_loss: 0.0000e+00 - total_loss: 1.0357 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 1s 261ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.9836 - regularization_loss: 0.0000e+00 - total_loss: 0.9836 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.9362 - regularization_loss: 0.0000e+00 - total_loss: 0.9362 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.8929 - regularization_loss: 0.0000e+00 - total_loss: 0.8929 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 1s 199ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.8532 - regularization_loss: 0.0000e+00 - total_loss: 0.8532 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 3s 519ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.8167 - regularization_loss: 0.0000e+00 - total_loss: 0.8167 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 1s 206ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.7830 - regularization_loss: 0.0000e+00 - total_loss: 0.7830 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 1s 263ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.7517 - regularization_loss: 0.0000e+00 - total_loss: 0.7517 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 1s 200ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.7227 - regularization_loss: 0.0000e+00 - total_loss: 0.7227 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 2s 336ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.6958 - regularization_loss: 0.0000e+00 - total_loss: 0.6958 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 3s 517ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.6706 - regularization_loss: 0.0000e+00 - total_loss: 0.6706 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 1s 201ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.6471 - regularization_loss: 0.0000e+00 - total_loss: 0.6471 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 3s 517ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.6251 - regularization_loss: 0.0000e+00 - total_loss: 0.6251 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 1s 276ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.6044 - regularization_loss: 0.0000e+00 - total_loss: 0.6044 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5850 - regularization_loss: 0.0000e+00 - total_loss: 0.5850 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5667 - regularization_loss: 0.0000e+00 - total_loss: 0.5667 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 3s 523ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5494 - regularization_loss: 0.0000e+00 - total_loss: 0.5494 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 1s 203ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5331 - regularization_loss: 0.0000e+00 - total_loss: 0.5331 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 1s 262ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5177 - regularization_loss: 0.0000e+00 - total_loss: 0.5177 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 1s 207ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.5031 - regularization_loss: 0.0000e+00 - total_loss: 0.5031 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 1s 199ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 0.4892 - regularization_loss: 0.0000e+00 - total_loss: 0.4892 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 102.0359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 102.0359\n",
            "6/6 [==============================] - 2s 249ms/step - factorized_top_k/top_1_categorical_accuracy: 0.5942 - factorized_top_k/top_5_categorical_accuracy: 0.9958 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 0.4791 - regularization_loss: 0.0000e+00 - total_loss: 0.4791\n",
            "7/7 [==============================] - 1s 145ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 173.3143 - regularization_loss: 0.0000e+00 - total_loss: 173.3143\n",
            "Top-100 accuracy (train): 1.00.\n",
            "Top-100 accuracy (test): 0.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next block creates a BruteForce index layer, which inherits from TopK. I pass my QueryModel to the constructor, which allows the index to accept _raw feature values_. This means I can pass in data to the index without worrying about String or Interger Lookup conversions. The BruteForce index layer returns a _Tuple of (top candidate scores, top candidate identifiers)_, for example a float value of 17.677254, which is the top K score, and the recommended barcode, as a string. I pass in the barcodes dataset to build the retrieval index. Something that's very important - which again, is something that I learned the hard way - is that this index is what you actually save when you save the model. So basically, this last BruteForce index layer becomes your final model. "
      ],
      "metadata": {
        "id": "5V0ld0mVXXxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
        "# recommends barcodes out of the entire barcodes dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((barcodes.batch(100), barcodes.batch(100).map(model.candidate_model)))\n",
        ")"
      ],
      "metadata": {
        "id": "ZLuryNa_GJEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7801cc-3dca-439a-9020-020bac8a9aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f8c51ea9570>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the index created, you can now use it to pass in your own query, independent of the training dataset. Here, I pass in a keto barcode, with a fat value of 15, and a carb value of 2. Earlier, I mentioned that the BruteForce Index returns of tuple of scores & barcodes. Here's where we can see what this looks like - and this is really important, because I'll need to handle this _output_ from my Android app.\n",
        "\n",
        "When I call the index, I can create my scores & barcode variables. Here, I just print out the scores. Notice how they are listed in decending order...based on what the model thinks is a good match.\n",
        "\n",
        "Then, I can iterate through the `barcodeRecommendations` and map the recommended barcodes to my training dataset, so I can see what type of products my model is recommending."
      ],
      "metadata": {
        "id": "d1WnUymuZIY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "scores, barcodeRecommendations = index({\n",
        "    \"code\": np.array([\"0078742028613\"]),\n",
        "    \"fat_value\": np.array([15]),\n",
        "    \"carbohydrates_value\": np.array([7]),\n",
        "    \"food_diet_type\": np.array([2])})\n",
        "\n",
        "print(scores)\n",
        "\n",
        "results = list(barcodeRecommendations[0].numpy().astype('str'))\n",
        "\n",
        "for x in results:\n",
        "  my_filtereddataset = train_ds.filter(lambda a: a['code'] == x)\n",
        "  print(next(iter(my_filtereddataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYiaho6lZI8n",
        "outputId": "fadaa7d2-6936-4a29-f858-c022dc14e668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[15.90346  15.740753 15.576517 14.641495 14.299671 13.997471 13.649216\n",
            "  13.423485 13.198267 12.905101]], shape=(1, 10), dtype=float32)\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0628915362343'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Tartinade \\xc3\\xa0 fromage \\xc3\\xa0 la cr\\xc3\\xa8me l\\xc3\\xa9g\\xc3\\xa8re'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=13>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742194639'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Turkey Breast'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742163536'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Medium Wing Sauce'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742230313'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Creamy Ceasar Dressing & Dip'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=40>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742065304'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Great value, mayonnaise, light, light'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=25>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742065212'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Great value, original ricotta cheese'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=15>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742027234'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Mandarin Oranges'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742201269'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Great Value Pecan Halves, 32 oz'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=20>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742075945'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Sour Cream'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=20>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=2>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742259192'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Sliced beets'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of those embedding layers, dense layers, and separate models can get pretty confusing. It would be great if we could call `model.summary()` to see what everything looks like, but I wasn't able to get that to work with this structure, even when I tried to call it after `model.fit`. What I can do is call `index.summary()` though. This gives us a little bit of info on the QueryModel. The parameters are all of my learnable features that the layer will weigh and evaluate during training."
      ],
      "metadata": {
        "id": "TZeZKI85IfmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRpVjQF2FllE",
        "outputId": "2488a0a3-1a0e-49a3-b6d5-97ed083bb8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"brute_force\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " query_model (QueryModel)    multiple                  101696    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 188,882\n",
            "Trainable params: 101,696\n",
            "Non-trainable params: 87,186\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`plot_model` is another way to visualize a model, but unfortunately for an index, I only get an image that says `brute_force`, with no other information."
      ],
      "metadata": {
        "id": "66ldq2YeKsJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(index, show_shapes=True, show_dtype=True, expand_nested=True, show_trainable=True) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "mMQl7mXTJyLO",
        "outputId": "3fb4f604-83a9-4fec-eb09-cc6b1fb16579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's pretty much it for creating the model - now, it's time to save it. First, I simply call `index.save`. If you try to do something like `model.save(path)`, you'll get an error - with this structure, I can only save the index. \n",
        "\n",
        "Instead of a temp or nested directory, I like to use a `./models` path, so the output file saves right to my Colab root directory; it's much easier to find it this way."
      ],
      "metadata": {
        "id": "iUX-Af23d2qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n",
        "# Export the query model.\n",
        "\n",
        "path = \"./models/product_recs\"\n",
        "print(path)\n",
        "\n",
        "index.save(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmF-BdywgsXM",
        "outputId": "f90b503f-d7ac-4eab-8ed7-140fa76b139b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./models/product_recs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I load up the saved index, and try it out. This time, I'll pass in a high carb diet type, and see what comes back."
      ],
      "metadata": {
        "id": "9NjNm12ReYdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load it back; can also be done in TensorFlow Serving.\n",
        "loaded = tf.saved_model.load(path)\n",
        "\n",
        "# Pass a food type in, get top predicted barcodes back.\n",
        "_, barcodeRecommendations = loaded({\n",
        "    \"code\": np.array([\"0078742370828\"]),\n",
        "    \"fat_value\": np.array([3]),\n",
        "    \"carbohydrates_value\": np.array([74]),\n",
        "    \"food_diet_type\": np.array([1])})\n",
        "\n",
        "results = list(barcodeRecommendations[0].numpy().astype('str'))\n",
        "\n",
        "for x in results:\n",
        "  my_filtereddataset = train_ds.filter(lambda a: a['code'] == x)\n",
        "  print(next(iter(my_filtereddataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCgEKsoaCk3h",
        "outputId": "1a8f470f-bdf3-4136-98b8-9af931706c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742370828'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Complete pancake & waffle mix'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=74>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742285481'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b\"Brown 'N Serve Dinner Rolls\">, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=52>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742183923'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Awake fruit yogurt cereal'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=84>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742114866'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'White Corn Tortillas'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=44>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742256757'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Complete pancake and waffle mix'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=74>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742067858'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Coffee Creamer'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=7>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=33>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742036601'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Texas toast thick sliced'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=52>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=1>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742146454'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Grilled white meat chicken and tender pasta in'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=9>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=14>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=5>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742062228'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Chunk White Chicken In Sauce'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n",
            "{'code': <tf.Tensor: shape=(), dtype=string, numpy=b'0078742010878'>, 'product_name_en': <tf.Tensor: shape=(), dtype=string, numpy=b'Great value, chunk white chicken with sun dried tomato and herb sauce'>, 'fat_value': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'carbohydrates_value': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'food_diet_type': <tf.Tensor: shape=(), dtype=int64, numpy=4>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`index.save` saves the model as a TensorFlow SavedModel, which we won't be able to use in Android yet. Next, we need to convert that SavedModel to a TensorFlow Lite model. Here, I faced another issue the first time around - I found that I needed to add TensorFlow ops support. Here's the error:\n",
        "\n",
        "```\n",
        "ConverterError: <unknown>:0: error: loc(fused[\"HashTableV2:\", \"hash_table\"]): 'tf.HashTableV2' op is neither a custom op nor a flex op\n",
        "```\n",
        "\n",
        "This is because of my IntegerLookups. Behind the scenes, the IntegerLookup embedding layers create a mapped table, which isn't included in the TensorFlow Lite builtin operator library. Luckily there's a workaround; I just needed to add the right converter options, and I was good to go.\n",
        ">Important: You'll need to add additional Android dependencies because of this issue too. I'll go over that once I'm finished with these last few steps in my Colab. \n",
        "\n",
        "For more information, you can check out this link: https://www.tensorflow.org/lite/guide/ops_select.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t5ut5pCT0dYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(path) # path to the SavedModel directory\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(path + '/product_recs.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "9S0HoH9fw6c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the hard part is done, it's time for some even harder stuff. I'm just kidding; sort of - this part is kinda fun. Once you download your TensorFlow Lite file, there's this awesome app called **Netron** that lets you visualize your model.\n",
        "\n",
        "Once it's loaded up, you can see:\n",
        "* Your inputs\n",
        "* Input datatypes\n",
        "* Input order - which is awesome\n",
        "* Outputs\n",
        "* Output datatypes\n",
        "* Output order\n",
        "\n",
        "This information is a must to know when we're ready to start sending and receiving inputs and outputs from our Android app. You can also see the HashTables that are created for the IntegerLookups, the BruteForce TopK layer, and all sorts of cool stuff. To the developers of Netron, I just want to say awesome job, and many thanks for this amazing tool. \n",
        "\n",
        "Here's the link for more information: https://github.com/lutzroeder/netron\n",
        "\n",
        "********\n",
        "In addition to Netron, we can also get an idea of how Android will handle _inputs_ and _outputs_ by using the TensorFlow Lite Interpreter. Here, I read my tflite file, then get the details about my inputs and outputs. Next, I use `interpreter.set_tensor` to set my input values. This is similar to how I used the `index` to get recommendation, but for the interpreter, I'm not using names. Instead, I use the input index, and send my inputs in the order they appear in the Netron preview. \n",
        "\n",
        "For the outputs, it's just like the index - the interpreter will bring back the scores & the barcode recommendations.\n",
        "\n",
        "My Android app also uses the TensorFlow Lite interpreter; so this is a really good preview of how things are going to work inside the app."
      ],
      "metadata": {
        "id": "_YwkI1WzQ_Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./models/product_recs\"\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=path + '/product_recs.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"input details...\")\n",
        "print(input_details)\n",
        "print(output_details)\n",
        "\n",
        "\n",
        "# Set inputs in order from 0 - 3. Use Netron to help. This will\n",
        "# be the same output array /android.\n",
        "interpreter.set_tensor(input_details[0]['index'], np.array([2], dtype=np.int64))\n",
        "interpreter.set_tensor(input_details[1]['index'], np.array([15], dtype=np.int64))\n",
        "interpreter.set_tensor(input_details[2]['index'], np.array([7], dtype=np.int64))\n",
        "interpreter.set_tensor(input_details[3]['index'], np.array([\"0078742028613\"], dtype=str))\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "scores = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"scores...\")\n",
        "print(scores)\n",
        "output_data = interpreter.get_tensor(output_details[1]['index'])\n",
        "print(\"recommendations...\")\n",
        "print(output_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMlnGriRqD3R",
        "outputId": "e6e25b48-6742-491e-c03a-69ef902fd071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input details...\n",
            "[{'name': 'serving_default_food_diet_type:0', 'index': 0, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_fat_value:0', 'index': 1, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_carbohydrates_value:0', 'index': 2, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.int64'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_code:0', 'index': 3, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.bytes_'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 29, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 31, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.bytes_'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "scores...\n",
            "[[15.903459 15.740753 15.576518 14.641494 14.299673 13.997471 13.649216\n",
            "  13.423485 13.198265 12.905102]]\n",
            "recommendations...\n",
            "[[b'0628915362343' b'0078742194639' b'0078742163536' b'0078742230313'\n",
            "  b'0078742065304' b'0078742065212' b'0078742027234' b'0078742201269'\n",
            "  b'0078742075945' b'0078742259192']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another handy tool is the TensorFlow Lite Analyzer. This by far gives us the most detail from Python. Here we can see the input shapes for the embedding layers, and dive a little deeper into the structure."
      ],
      "metadata": {
        "id": "y4FLNjQeMDrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.lite.experimental.Analyzer.analyze(model_path=path + '/product_recs.tflite')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwgqmpRJ1MA9",
        "outputId": "b7fa0b92-f800-4fe8-fa80-40be383c0a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ./models/product_recs/product_recs.tflite ===\n",
            "\n",
            "Your TFLite model has '2' subgraph(s). In the subgraph description below,\n",
            "T# represents the Tensor numbers. For example, in Subgraph#0, the CALL_ONCE op takes\n",
            " as input and produces  as output.\n",
            "\n",
            "Subgraph#0 main(T#0, T#1, T#2, T#3) -> [T#29, T#31]\n",
            "  Op#0 CALL_ONCE(Subgraph#1) -> []\n",
            "  Op#1 FlexHashTableV2() -> [T#14]\n",
            "  Op#2 FlexHashTableV2() -> [T#15]\n",
            "  Op#3 FlexHashTableV2() -> [T#16]\n",
            "  Op#4 FlexHashTableV2() -> [T#17]\n",
            "  Op#5 FlexLookupTableFindV2(T#14, T#2, T#12) -> [T#18]\n",
            "  Op#6 GATHER(T#7, T#18) -> [T#19]\n",
            "  Op#7 FlexLookupTableFindV2(T#17, T#3, T#12) -> [T#20]\n",
            "  Op#8 GATHER(T#8, T#20) -> [T#21]\n",
            "  Op#9 FlexLookupTableFindV2(T#15, T#1, T#12) -> [T#22]\n",
            "  Op#10 GATHER(T#9, T#22) -> [T#23]\n",
            "  Op#11 FlexLookupTableFindV2(T#16, T#0, T#12) -> [T#24]\n",
            "  Op#12 GATHER(T#10, T#24) -> [T#25]\n",
            "  Op#13 CONCATENATION(T#21, T#25, T#23, T#19) -> [T#26]\n",
            "  Op#14 FULLY_CONNECTED(T#26, T#13, T#4) -> [T#27]\n",
            "  Op#15 FULLY_CONNECTED(T#27, T#5, T#-1) -> [T#28]\n",
            "  Op#16 TOPK_V2(T#28, T#6[10]) -> [T#29, T#30]\n",
            "  Op#17 GATHER(T#11, T#30) -> [T#31]\n",
            "\n",
            "Tensors of Subgraph#0\n",
            "  T#0(serving_default_food_diet_type:0) shape_signature:[-1], type:INT64\n",
            "  T#1(serving_default_fat_value:0) shape_signature:[-1], type:INT64\n",
            "  T#2(serving_default_carbohydrates_value:0) shape_signature:[-1], type:INT64\n",
            "  T#3(serving_default_code:0) shape_signature:[-1], type:STRING\n",
            "  T#4(brute_force/query_model/sequential_4/dense/BiasAdd/ReadVariableOp) shape:[32], type:FLOAT32 RO 128 bytes, buffer: 5, data:[0.0150791, -0.0589705, -0.0853867, 0.0450657, -0.0384624, ...]\n",
            "  T#5(brute_force/MatMul/ReadVariableOp) shape:[2642, 32], type:FLOAT32 RO 338176 bytes, buffer: 6, data:[0.425743, 0.346312, -0.419638, 0.305342, 0.114899, ...]\n",
            "  T#6(brute_force/TopKV2/k) shape:[], type:INT32 RO 4 bytes, buffer: 7, data:[10]\n",
            "  T#7(brute_force/query_model/item_model/sequential_3/embedding_3/embedding_lookup) shape:[200, 32], type:FLOAT32 RO 25600 bytes, buffer: 8, data:[0.119983, 0.00146249, 0.127104, -0.178735, 0.192101, ...]\n",
            "  T#8(brute_force/query_model/item_model/sequential/embedding/embedding_lookup) shape:[2643, 32], type:FLOAT32 RO 338304 bytes, buffer: 9, data:[0.0383492, -0.00208938, 0.0186241, -0.00579778, -0.0478703, ...]\n",
            "  T#9(brute_force/query_model/item_model/sequential_2/embedding_2/embedding_lookup) shape:[200, 32], type:FLOAT32 RO 25600 bytes, buffer: 10, data:[0.0923546, 0.291001, -0.0170482, -0.107488, 0.308285, ...]\n",
            "  T#10(brute_force/query_model/item_model/sequential_1/embedding_1/embedding_lookup) shape:[6, 32], type:FLOAT32 RO 768 bytes, buffer: 11, data:[-0.0301688, -0.0380926, -0.014384, 0.0243783, 0.0370518, ...]\n",
            "  T#11(brute_force/Gather) shape:[2642], type:STRING RO 44643 bytes, buffer: 12, data:[R, \n",
            ", ., ., P, ...]\n",
            "  T#12(Const_10) shape:[], type:INT64 RO 8 bytes, buffer: 13, data:[??, ??, ??, ??, ??, ...]\n",
            "  T#13(brute_force/query_model/sequential_4/dense/MatMul1) shape:[32, 128], type:FLOAT32 RO 16384 bytes, buffer: 14, data:[-0.144723, 0.92597, 0.238375, 0.61273, 0.530761, ...]\n",
            "  T#14(hash_table) shape:[], type:RESOURCE\n",
            "  T#15(hash_table_1) shape:[], type:RESOURCE\n",
            "  T#16(hash_table_2) shape:[], type:RESOURCE\n",
            "  T#17(hash_table_3) shape:[], type:RESOURCE\n",
            "  T#18(brute_force/query_model/item_model/sequential_3/integer_lookup_2/None_Lookup/LookupTableFindV2) shape:[], type:INT64\n",
            "  T#19(brute_force/query_model/item_model/sequential_3/embedding_3/embedding_lookup;Const_10) shape:[], type:FLOAT32\n",
            "  T#20(brute_force/query_model/item_model/sequential/string_lookup/None_Lookup/LookupTableFindV2) shape:[], type:INT64\n",
            "  T#21(brute_force/query_model/item_model/sequential/embedding/embedding_lookup;Const_10) shape:[], type:FLOAT32\n",
            "  T#22(brute_force/query_model/item_model/sequential_2/integer_lookup_1/None_Lookup/LookupTableFindV2) shape:[], type:INT64\n",
            "  T#23(brute_force/query_model/item_model/sequential_2/embedding_2/embedding_lookup;Const_10) shape:[], type:FLOAT32\n",
            "  T#24(brute_force/query_model/item_model/sequential_1/integer_lookup/None_Lookup/LookupTableFindV2) shape:[], type:INT64\n",
            "  T#25(brute_force/query_model/item_model/sequential_1/embedding_1/embedding_lookup;Const_10) shape:[], type:FLOAT32\n",
            "  T#26(brute_force/query_model/item_model/concat) shape:[], type:FLOAT32\n",
            "  T#27(brute_force/query_model/sequential_4/dense/MatMul;brute_force/query_model/sequential_4/dense/BiasAdd) shape_signature:[-1, 32], type:FLOAT32\n",
            "  T#28(brute_force/MatMul) shape_signature:[-1, 2642], type:FLOAT32\n",
            "  T#29(StatefulPartitionedCall:0) shape_signature:[-1, 10], type:FLOAT32\n",
            "  T#30(brute_force/TopKV2) shape_signature:[-1, 10], type:INT32\n",
            "  T#31(StatefulPartitionedCall:1) shape_signature:[-1, 10], type:STRING\n",
            "\n",
            "Subgraph#1 NoOp() -> []\n",
            "  Op#0 FlexHashTableV2() -> [T#1_4]\n",
            "  Op#1 FlexLookupTableImportV2(T#1_4, T#1_3, T#1_3) -> []\n",
            "  Op#2 FlexHashTableV2() -> [T#1_5]\n",
            "  Op#3 FlexLookupTableImportV2(T#1_5, T#1_3, T#1_3) -> []\n",
            "  Op#4 FlexHashTableV2() -> [T#1_6]\n",
            "  Op#5 FlexLookupTableImportV2(T#1_6, T#1_2, T#1_2) -> []\n",
            "  Op#6 FlexHashTableV2() -> [T#1_7]\n",
            "  Op#7 FlexLookupTableImportV2(T#1_7, T#1_0, T#1_1) -> []\n",
            "\n",
            "Tensors of Subgraph#1\n",
            "  T#1_0(Const_7) shape:[2642], type:STRING RO 44643 bytes, buffer: 33, data:[R, \n",
            ", ., ., P, ...]\n",
            "  T#1_1(Const_6) shape:[2642], type:INT64 RO 21136 bytes, buffer: 34, data:[??, ??, ??, ??, ??, ...]\n",
            "  T#1_2(Const_4) shape:[5], type:INT64 RO 40 bytes, buffer: 35, data:[??, ??, ??, ??, ??, ...]\n",
            "  T#1_3(Const) shape:[199], type:INT64 RO 1592 bytes, buffer: 36, data:[??, ??, ??, ??, ??, ...]\n",
            "  T#1_4(hash_table1) shape:[], type:RESOURCE\n",
            "  T#1_5(hash_table_11) shape:[], type:RESOURCE\n",
            "  T#1_6(hash_table_21) shape:[], type:RESOURCE\n",
            "  T#1_7(hash_table_31) shape:[], type:RESOURCE\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Your TFLite model has '1' signature_def(s).\n",
            "\n",
            "Signature#0 key: 'serving_default'\n",
            "- Subgraph: Subgraph#0\n",
            "- Inputs: \n",
            "    'carbohydrates_value' : T#2\n",
            "    'code' : T#3\n",
            "    'fat_value' : T#1\n",
            "    'food_diet_type' : T#0\n",
            "- Outputs: \n",
            "    'output_1' : T#29\n",
            "    'output_2' : T#31\n",
            "\n",
            "---------------------------------------------------------------\n",
            "              Model size:     865680 bytes\n",
            "    Non-data buffer size:       8546 bytes (00.99 %)\n",
            "  Total data buffer size:     857134 bytes (99.01 %)\n",
            "          - Subgraph#0  :     789615 bytes (91.21 %)\n",
            "          - Subgraph#1  :      67411 bytes (07.79 %)\n",
            "    (Zero value buffers):          8 bytes (00.00 %)\n",
            "\n",
            "* Buffers of TFLite model are mostly used for constant tensors.\n",
            "  And zero value buffers are buffers filled with zeros.\n",
            "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
            "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![trophy-win.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "6buXxiYdxSZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, I've won the first half of the fight, and my model coding is done! \n",
        "Now, it's time to import the model into Firebase. You can do this automatically if you'd like to, which would be awesome for an automated, CI/CD pipeline. There are quite a few steps involved though, so for me, it was just easier to download the tflite file. If you'd like to learn more about the Firebase ML SDK, check out this link:\n",
        "\n",
        "https://colab.research.google.com/github/firebase/quickstart-python/blob/master/machine-learning/Firebase_ML_API_Tutorial.ipynb"
      ],
      "metadata": {
        "id": "XLPwLaZ9Oks8"
      }
    }
  ]
}